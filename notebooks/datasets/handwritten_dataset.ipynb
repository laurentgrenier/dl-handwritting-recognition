{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../config/local.ipynb\"\n",
    "%run \"../utils/functions.ipynb\"\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from src.mrcnn.utils import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandwrittenDataset(Dataset):    \n",
    "    \n",
    "    def __init__(self, \n",
    "                images_path, \n",
    "                labels_file_path,\n",
    "                classes=None,\n",
    "                stage: str = \"train\",\n",
    "                img_ids: np.array = None,\n",
    "                transforms=None,\n",
    "                size=(512,512)):\n",
    "        super().__init__()                \n",
    "        # Add classes\n",
    "        self.init_classes(classes)\n",
    "        # input files paths        \n",
    "        self.images_dir_path = images_path\n",
    "        self.labels_file_path = labels_file_path\n",
    "        # images ids         \n",
    "        self.img_ids = img_ids\n",
    "        # data transformation function\n",
    "        self.transforms = transforms\n",
    "        # load referenced masks        \n",
    "        self.load_masks_references()        \n",
    "        # load the images \n",
    "        self.load_images()\n",
    "        \n",
    "    def init_classes(self, classes):\n",
    "        \"\"\" add classes \"\"\"\n",
    "        for item in classes:\n",
    "            self.add_class(item['source'], int(item['num']), item['name'])                            \n",
    "            \n",
    "    def load_images(self):\n",
    "        \"\"\" Generate the images list\n",
    "        \"\"\"\n",
    "        # Add images\n",
    "        for idx in range(len(self.img_ids)):        \n",
    "            self.add_image(\"pages\", image_id=idx, path=os.path.join(self.images_dir_path, self.img_ids[idx]), name=self.img_ids[idx])        \n",
    "    \n",
    "    def load_masks_references(self): \n",
    "        # load all masks\n",
    "        all_masks = pd.read_csv(self.labels_file_path)        \n",
    "        all_masks = all_masks.set_index(['name', 'num'])                \n",
    "        \n",
    "        # filter the masks by images ids\n",
    "        self.masks_references = all_masks.loc[self.img_ids].index.get_level_values(['name', 'num'])\n",
    "        \n",
    "        print(\"finish load_masks_references\")\n",
    "        \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        img = self.image_info[image_id]\n",
    "        \n",
    "        # image name\n",
    "        name = img['name']\n",
    "        \n",
    "        # check if the image is referenced\n",
    "        if not name in self.masks_references.index:\n",
    "            return None, []\n",
    "        \n",
    "        # list of labels     \n",
    "        labels = self.masks_references.loc[name]['label']\n",
    "        \n",
    "        if type(labels) is str:\n",
    "            labels = [labels]\n",
    "        else:\n",
    "            labels = list(labels)\n",
    "        \n",
    "        masks = np.array(list(refs.loc[name]['mask'].apply(lambda v: rle_to_mask(v, size[0], size[1]))))\n",
    "                \n",
    "        # map the labels to the class indexes\n",
    "        class_ids = np.array([self.class_names.index(label) for label in labels])    \n",
    "        \n",
    "        # create the masks tensor\n",
    "        masks_tensor = np.array([mask.astype(np.bool) for mask in masks])\n",
    "                \n",
    "        return np.stack(masks_tensor,axis=-1), class_ids.astype(np.int32)\n",
    "    \n",
    "    def get_random_image(self, min_label_count=0):\n",
    "        \"\"\" return a filename and a (widht, height, RGB) array of a randmly selected image\n",
    "        with a label !\n",
    "        \"\"\"\n",
    "        # idx = random.randint(0,len(self.image_info)-1)   \n",
    "        # img = self.image_info[idx]\n",
    "        \n",
    "        # pick an image id from the masks references \n",
    "        # refs_idx = random.randint(0,len(self.masks_references.index)-1)   \n",
    "        # img_id = self.masks_references.index[refs_idx]\n",
    "        \n",
    "        # list of multi-label image\n",
    "        df = self.masks_references.reset_index()\n",
    "        df_a = df.groupby('name').count() >= min_label_count\n",
    "        multi_labels = list(df_a[df_a['label']].index)\n",
    "\n",
    "        # random selection of an image\n",
    "        ref_idx = random.randint(0,len(multi_labels))    \n",
    "        img_id = multi_labels[ref_idx]\n",
    "        \n",
    "        idx = [info['id'] for info in self.image_info if info['name'] == img_id][0]        \n",
    "                \n",
    "        return idx, self.load_image(idx)\n",
    "    \n",
    "    def get_transformation(self, image_id):\n",
    "        # load the image\n",
    "        img = self.load_image(image_id)\n",
    "        # img = img.astype(np.uint8)\n",
    "        \n",
    "        # get the mask\n",
    "        masks, class_ids = self.load_mask(image_id)\n",
    "        \n",
    "        # image name        \n",
    "        img_infos = self.image_info[image_id]\n",
    "        img_name = img_infos['name']\n",
    "        \n",
    "        # img = img.astype(np.uint8)\n",
    "        \n",
    "        data = {\"image\": img} \n",
    "        \n",
    "        # add each mask for the transformation\n",
    "        for i in range(len(class_ids)):\n",
    "            idx = 'mask{}'.format(i)\n",
    "            mask = masks[:,:,i].astype(np.uint8)\n",
    "            data[idx] = mask    \n",
    "        \n",
    "        # m = masks[:,:,0].astype(np.uint8)\n",
    "        \n",
    "        # apply augementation\n",
    "        transformer = self.__get_training_transformer(data)        \n",
    "        augmented = transformer(**data)\n",
    "\n",
    "        # augmented image\n",
    "        img = augmented['image']\n",
    "        \n",
    "        # list of augmented masks\n",
    "        tranformed_masks = [augmented[key].astype(bool) for key in augmented.keys() if not key == 'image']\n",
    "        \n",
    "        return img, np.stack(tranformed_masks,axis=-1)\n",
    "    \n",
    "    def __get_training_transformer(self, data):\n",
    "        \"\"\" Return  the albumentation transformation function with respect to the number of masks         \n",
    "        \"\"\"\n",
    "        train_transform = [\n",
    "            albu.HorizontalFlip(p=0.5),\n",
    "            albu.VerticalFlip(p=0.5),\n",
    "            albu.Blur(p=0.5),\n",
    "            albu.ShiftScaleRotate(\n",
    "                scale_limit=0.5,\n",
    "                rotate_limit=0,\n",
    "                shift_limit=0.1,\n",
    "                p=0.5,\n",
    "                border_mode=0\n",
    "            ),\n",
    "            albu.GridDistortion(p=0.5),        \n",
    "        ]\n",
    "        \n",
    "        target = {}\n",
    "        for i in range(len(data.keys()) -1):\n",
    "            target['mask' + str(i)] = 'mask'            \n",
    "        return albu.Compose(train_transform, additional_targets=target)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(masks_path, fold_num=0, n_folds=4, seed=42):\n",
    "    \"\"\"\n",
    "    return train and validation ids from the label file\n",
    "    parameters:\n",
    "        model_no: the model number if you train multiples models with the same data\n",
    "        n_folds: number of folds to create \n",
    "    \"\"\"\n",
    "    \n",
    "    df_masks = pd.read_csv(masks_path)\n",
    "                \n",
    "    # get count of label by file\n",
    "    refs = df_masks.groupby('name').count().reset_index()\n",
    "    \n",
    "    # define the kfold generator\n",
    "    skfolds = StratifiedKFold(n_splits=n_folds,random_state=seed)\n",
    "    \n",
    "    # create the folds\n",
    "    folds = [[train_idxs, valid_idxs] for train_idxs, valid_idxs in skfolds.split(refs['name'], refs['label'])]\n",
    "    sampled_train_ids = list(refs.iloc[folds[fold_num][0]]['name'])\n",
    "    sampled_valid_ids = list(refs.iloc[folds[fold_num][1]]['name'])\n",
    "    \n",
    "    return sampled_train_ids, sampled_valid_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ids: 131 items, valid_ids: 44 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laurent/workspaces/mooke/github/dl-handwritting-recognition/p_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/home/laurent/workspaces/mooke/github/dl-handwritting-recognition/p_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_ids, valid_ids = train_valid_split(MASKS_FILE)\n",
    "print(\"train_ids: {} items, valid_ids: {} items\".format(len(train_ids), len(valid_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build train and valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_valid_dataset(images_path, masks_path, classes, seed=42):\n",
    "    # get train and validation ids    \n",
    "    train_ids, valid_ids = train_valid_split(masks_path=masks_path, seed=seed)\n",
    "    \n",
    "    # Training dataset\n",
    "    dataset_train = HandwrittenDataset(images_path=images_path,\n",
    "                                  labels_file_path=masks_path,\n",
    "                                  classes=classes,\n",
    "                                 img_ids=train_ids,\n",
    "                                 transforms=get_training_augmentation())\n",
    "    dataset_train.prepare()\n",
    "    \n",
    "    # Validation dataset\n",
    "    dataset_val = HandwrittenDataset(images_path=images_path, \n",
    "                                labels_file_path=masks_path,\n",
    "                                classes=classes,\n",
    "                                img_ids=valid_ids,\n",
    "                                transforms=get_training_augmentation())\n",
    "    dataset_val.prepare()\n",
    "    \n",
    "    return dataset_train, dataset_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laurent/workspaces/mooke/github/dl-handwritting-recognition/p_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/home/laurent/workspaces/mooke/github/dl-handwritting-recognition/p_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Level ['name', 'num'] not found\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/workspaces/mooke/github/dl-handwritting-recognition/p_env/lib/python3.6/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_number\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ['name', 'num'] is not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-af6a8735f8ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'clouds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Fish'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_train_valid_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESIZED_512x512_FEATURES_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMASKS_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-128-6816ecc5fd82>\u001b[0m in \u001b[0;36mbuild_train_valid_dataset\u001b[0;34m(images_path, masks_path, classes, seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m                                   \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                  \u001b[0mimg_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                  transforms=get_training_augmentation())\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-ac3e49d6ce08>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, images_path, labels_file_path, classes, stage, img_ids, transforms, size)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# load referenced masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_masks_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# load the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-ac3e49d6ce08>\u001b[0m in \u001b[0;36mload_masks_references\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# filter the masks by images ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks_references\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finish load_masks_references\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspaces/mooke/github/dl-handwritting-recognition/p_env/lib/python3.6/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_level_values\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1596\u001b[0m         \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'e'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'level_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \"\"\"\n\u001b[0;32m-> 1598\u001b[0;31m         \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1599\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspaces/mooke/github/dl-handwritting-recognition/p_env/lib/python3.6/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_number\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Level %s not found\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Level ['name', 'num'] not found\""
     ]
    }
   ],
   "source": [
    "classes = [{'source':'clouds', 'num':1, 'name':'Fish'}]\n",
    "train_ds, val_ds = build_train_valid_dataset(RESIZED_512x512_FEATURES_DIR, MASKS_FILE, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.get_random_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
